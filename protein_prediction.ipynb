{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load sequences from a file\n",
    "def load_sequences(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    current_sequence = []\n",
    "    current_label = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('>'):\n",
    "            if current_sequence:\n",
    "                sequences.append(''.join(current_sequence))\n",
    "                labels.append(current_label)\n",
    "                current_sequence = []\n",
    "            current_label = line[1:]  # Remove the '>'\n",
    "        else:\n",
    "            current_sequence.append(line)\n",
    "\n",
    "    # Add the last sequence\n",
    "    if current_sequence:\n",
    "        sequences.append(''.join(current_sequence))\n",
    "        labels.append(current_label)\n",
    "\n",
    "    return sequences, labels\n",
    "\n",
    "# Load the data\n",
    "file_path = r'' # add filepath \n",
    "sequences, labels = load_sequences(file_path)\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({'sequence': sequences, 'label': labels})\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "# Define structural and non-structural protein types\n",
    "structural_proteins = ['CORE', 'E1', 'E2']\n",
    "non_structural_proteins = ['NS2', 'NS3', 'NS4A', 'NS4B', 'NS5A', 'NS5B']\n",
    "\n",
    "# Initialize lists to store data\n",
    "sequences = []\n",
    "labels = []\n",
    "broad_labels = []\n",
    "\n",
    "# Parse FASTA file\n",
    "with open(r'', 'r') as fasta_file:                                            #Add file path\n",
    "    for record in SeqIO.parse(fasta_file, 'fasta'):\n",
    "        # Extract sequence and type from header\n",
    "        sequence = str(record.seq)\n",
    "        protein_type = record.description.split()[0]  # Assuming protein type is in the header after the sequence ID\n",
    "        \n",
    "        # Assign broad labels (Structural vs Non-Structural)\n",
    "        if protein_type in structural_proteins:\n",
    "            broad_label = 'Structural'\n",
    "        elif protein_type in non_structural_proteins:\n",
    "            broad_label = 'Non-Structural'\n",
    "        else:\n",
    "            broad_label = 'Unknown'  # Handle unexpected types\n",
    "\n",
    "        # Append sequence and labels\n",
    "        sequences.append(sequence)\n",
    "        labels.append(protein_type)  # Specific protein label (e.g., 'Core', 'NS5A')\n",
    "        broad_labels.append(broad_label)  # Broad label (e.g., 'Structural', 'Non-Structural')\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame({\n",
    "    'sequence': sequences,\n",
    "    'label': labels,\n",
    "    'broad_label': broad_labels\n",
    "})\n",
    "\n",
    "# Preview the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode broad labels (Structural, Non-Structural)\n",
    "broad_label_encoder = LabelEncoder()\n",
    "df['broad_label_encoded'] = broad_label_encoder.fit_transform(df['broad_label'])\n",
    "\n",
    "# Encode specific protein types (Core, NS5A, etc.)\n",
    "protein_label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = protein_label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# Print some encoded values for verification\n",
    "print(f\"Sample encoded labels: {df['label_encoded'].head().tolist()}\")\n",
    "print(f\"Sample hierarchical labels: {df['broad_label_encoded'].head().tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# One-hot encoding of specific protein labels\n",
    "df['label_one_hot'] = list(to_categorical(df['label_encoded']))\n",
    "\n",
    "# One-hot encoding of broad labels\n",
    "df['broad_label_one_hot'] = list(to_categorical(df['broad_label_encoded']))\n",
    "\n",
    "print(f\"Sample one-hot encoded labels: {df['label_one_hot'].head()}\")\n",
    "print(f\"Sample one-hot encoded broad labels: {df['broad_label_one_hot'].head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Encode sequences into integer values\n",
    "amino_acid_mapping = {aa: idx for idx, aa in enumerate(set(''.join(sequences)))}\n",
    "sequences_encoded = [[amino_acid_mapping[aa] for aa in seq] for seq in sequences]\n",
    "\n",
    "# Pad sequences\n",
    "max_len = max(len(seq) for seq in sequences_encoded)\n",
    "X = pad_sequences(sequences_encoded, maxlen=max_len, padding='post')\n",
    "\n",
    "# Convert to numpy array for TensorFlow compatibility\n",
    "X = np.array([to_categorical(seq, num_classes=len(amino_acid_mapping)) for seq in X])\n",
    "\n",
    "# Prepare labels\n",
    "y = np.array(df['label_one_hot'].tolist())\n",
    "y_broad = np.array(df['broad_label_one_hot'].tolist())\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test, y_broad_train, y_broad_test = train_test_split(\n",
    "    X, y, y_broad, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Encode sequences into integer values\n",
    "amino_acid_mapping = {aa: idx for idx, aa in enumerate(set(''.join(sequences)))}\n",
    "sequences_encoded = [[amino_acid_mapping[aa] for aa in seq] for seq in sequences]\n",
    "\n",
    "# Pad sequences\n",
    "max_len = max(len(seq) for seq in sequences_encoded)\n",
    "X = pad_sequences(sequences_encoded, maxlen=max_len, padding='post')\n",
    "\n",
    "# Convert to one-hot encoding\n",
    "X = np.array([to_categorical(seq, num_classes=len(amino_acid_mapping)) for seq in X])\n",
    "\n",
    "# Prepare labels\n",
    "y = np.array(df['label_one_hot'].tolist())\n",
    "y_broad = np.array(df['broad_label_one_hot'].tolist())\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test, y_broad_train, y_broad_test = train_test_split(\n",
    "    X, y, y_broad, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "print(f\"Training broad labels shape: {y_broad_train.shape}\")\n",
    "print(f\"Testing broad labels shape: {y_broad_test.shape}\")\n",
    "print(f\"Training detailed labels shape: {y_train.shape}\")\n",
    "print(f\"Testing detailed labels shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Define the model inputs\n",
    "input_seq = Input(shape=(max_len, len(amino_acid_mapping)))\n",
    "\n",
    "# Define LSTM layers\n",
    "x = LSTM(256, return_sequences=True)(input_seq)\n",
    "x = LSTM(256)(x)\n",
    "\n",
    "# Define the two outputs\n",
    "broad_output = Dense(len(broad_label_encoder.classes_), activation='softmax', name='broad_output')(x)\n",
    "detailed_output = Dense(len(protein_label_encoder.classes_), activation='softmax', name='detailed_output')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_seq, outputs=[broad_output, detailed_output])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'broad_output': 'categorical_crossentropy', 'detailed_output': 'categorical_crossentropy'},\n",
    "              metrics={'broad_output': 'accuracy', 'detailed_output': 'accuracy'})\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # What to monitor\n",
    "    patience=3,  # Number of epochs with no improvement to wait\n",
    "    restore_best_weights=True  # Restore the weights of the best model\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {'broad_output': y_broad_train, 'detailed_output': y_train},\n",
    "    epochs=10,  # Adjust the number of epochs as needed\n",
    "    batch_size=32,  # Adjust the batch size as needed\n",
    "    validation_split=0.2,  # Use 20% of training data for validation\n",
    "    callbacks=[early_stopping]  # Add the EarlyStopping callback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, broad_loss, detailed_loss, broad_acc, detailed_acc = model.evaluate(\n",
    "    X_test,\n",
    "    {'broad_output': y_broad_test, 'detailed_output': y_test}\n",
    ")\n",
    "\n",
    "print(f'Broad classification loss: {broad_loss}')\n",
    "print(f'Detailed classification loss: {detailed_loss}')\n",
    "print(f'Broad classification accuracy: {broad_acc}')\n",
    "print(f'Detailed classification accuracy: {detailed_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict probabilities for test set\n",
    "y_broad_pred_prob = model.predict(X_test)[0]  # Probabilities for broad labels\n",
    "y_detailed_pred_prob = model.predict(X_test)[1]  # Probabilities for detailed labels\n",
    "\n",
    "# For binary classification\n",
    "print(\"Classification report for broad labels:\")\n",
    "print(classification_report(np.argmax(y_broad_test, axis=1), np.argmax(y_broad_pred_prob, axis=1), target_names=broad_label_encoder.classes_))\n",
    "\n",
    "print(\"Classification report for detailed labels:\")\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_detailed_pred_prob, axis=1), target_names=protein_label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#CROSS VALIDATION \n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Set up k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # Using 5-fold cross-validation\n",
    "\n",
    "# Initialize lists to store results\n",
    "fold_accuracy = []\n",
    "fold_broad_accuracy = []\n",
    "fold_detailed_accuracy = []\n",
    "\n",
    "# Iterate through each fold\n",
    "fold_num = 1\n",
    "for train_index, val_index in kf.split(X):\n",
    "    print(f\"\\nTraining Fold {fold_num}...\")\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "    y_broad_train_fold, y_broad_val_fold = y_broad[train_index], y_broad[val_index]\n",
    "\n",
    "    # Define the model (reinitialize for each fold)\n",
    "    input_seq = Input(shape=(max_len, len(amino_acid_mapping)))\n",
    "    x = LSTM(256, return_sequences=True)(input_seq)\n",
    "    x = LSTM(256)(x)\n",
    "    broad_output = Dense(len(broad_label_encoder.classes_), activation='softmax', name='broad_output')(x)\n",
    "    detailed_output = Dense(len(protein_label_encoder.classes_), activation='softmax', name='detailed_output')(x)\n",
    "    model = Model(inputs=input_seq, outputs=[broad_output, detailed_output])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'broad_output': 'categorical_crossentropy', 'detailed_output': 'categorical_crossentropy'},\n",
    "                  metrics={'broad_output': 'accuracy', 'detailed_output': 'accuracy'})\n",
    "\n",
    "    # Train the model for the current fold\n",
    "    history = model.fit(\n",
    "        X_train_fold,\n",
    "        {'broad_output': y_broad_train_fold, 'detailed_output': y_train_fold},\n",
    "        epochs=10,  # Adjust the number of epochs\n",
    "        batch_size=32,  # Adjust batch size if needed\n",
    "        validation_data=(X_val_fold, {'broad_output': y_broad_val_fold, 'detailed_output': y_val_fold}),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the validation set for this fold\n",
    "    scores = model.evaluate(X_val_fold, {'broad_output': y_broad_val_fold, 'detailed_output': y_val_fold}, verbose=0)\n",
    "\n",
    "    \n",
    "    # Print and store accuracy results\n",
    "    print(f\"Fold {fold_num} - Broad classification accuracy: {scores[3]:.4f}\")\n",
    "    print(f\"Fold {fold_num} - Detailed classification accuracy: {scores[4]:.4f}\")\n",
    "\n",
    "    # Store accuracy results\n",
    "    fold_broad_accuracy.append(scores[3])  # Broad classification accuracy\n",
    "    fold_detailed_accuracy.append(scores[4])  # Detailed classification accuracy\n",
    "    fold_num += 1\n",
    "\n",
    "# Print average accuracy across all folds\n",
    "print(\"\\nCross-validation results:\")\n",
    "print(f\"Average Broad Classification Accuracy: {np.mean(fold_broad_accuracy):.4f}\")\n",
    "print(f\"Average Detailed Classification Accuracy: {np.mean(fold_detailed_accuracy):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_protein_type(sequence, model, amino_acid_mapping, max_seq_length, broad_label_encoder, protein_label_encoder):\n",
    "    # Preprocess the sequence\n",
    "    processed_sequence = preprocess_sequence(sequence, max_seq_length, amino_acid_mapping)\n",
    "    \n",
    "    # Ensure the shape of the processed sequence matches the expected input shape of the model\n",
    "    expected_shape = (1, max_seq_length, len(amino_acid_mapping))\n",
    "    if processed_sequence.shape != expected_shape:\n",
    "        raise ValueError(f\"Expected input shape {expected_shape} but got {processed_sequence.shape}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    broad_pred, detailed_pred = model.predict(processed_sequence)\n",
    "    \n",
    "    # Get the index of the maximum probability for broad and detailed predictions\n",
    "    broad_pred_index = np.argmax(broad_pred, axis=1)[0]\n",
    "    detailed_pred_index = np.argmax(detailed_pred, axis=1)[0]\n",
    "    \n",
    "    # Validate indices against label encoders\n",
    "    if broad_pred_index >= len(broad_label_encoder.classes_):\n",
    "        raise ValueError(f\"Broad prediction index {broad_pred_index} is out of bounds for encoder classes.\")\n",
    "    if detailed_pred_index >= len(protein_label_encoder.classes_):\n",
    "        raise ValueError(f\"Detailed prediction index {detailed_pred_index} is out of bounds for encoder classes.\")\n",
    "    \n",
    "    # Get the corresponding labels\n",
    "    broad_pred_label = broad_label_encoder.inverse_transform([broad_pred_index])[0]\n",
    "    detailed_pred_label = protein_label_encoder.inverse_transform([detailed_pred_index])[0]\n",
    "    \n",
    "    return broad_pred_label, detailed_pred_label\n",
    "\n",
    "# Define max_seq_length and amino_acid_mapping\n",
    "max_seq_length = 261  # Adjust based on your training data\n",
    "amino_acid_mapping = {aa: idx for idx, aa in enumerate(set(''.join(sequences)))} # Replace with your actual mapping\n",
    "\n",
    "# Example usage\n",
    "new_sequence = ''\n",
    "broad_pred_label, detailed_pred_label = predict_protein_type(\n",
    "    new_sequence, model, amino_acid_mapping, max_seq_length, broad_label_encoder, protein_label_encoder\n",
    ")\n",
    "\n",
    "print(\"Predicted broad label:\", broad_pred_label)\n",
    "print(\"Predicted detailed label:\", detailed_pred_label)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
