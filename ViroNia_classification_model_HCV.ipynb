{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP1: INSTALL BIOPYTHON, TENSORFLOW-KERAS, SCIKIT-LEARN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2: IMPORT LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3: LOAD SEQUENCES\n",
    "\n",
    "def load_sequences(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    current_sequence = []\n",
    "    current_label = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('>'):\n",
    "            if current_sequence:\n",
    "                sequences.append(''.join(current_sequence))\n",
    "                labels.append(current_label)\n",
    "                current_sequence = []\n",
    "            current_label = line[1:]  # Remove the '>'\n",
    "        else:\n",
    "            current_sequence.append(line)\n",
    "\n",
    "    # Add the last sequence\n",
    "    if current_sequence:\n",
    "        sequences.append(''.join(current_sequence))\n",
    "        labels.append(current_label)\n",
    "\n",
    "    return sequences, labels\n",
    "\n",
    "file_path = r'()' #Enter your file_path\n",
    "sequences, labels = load_sequences(file_path)\n",
    "\n",
    "# Convert sequences to a dataframe\n",
    "data = pd.DataFrame({'sequence': sequences, 'label': labels})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 4: UNIQUE CHARACTERS\n",
    "\n",
    "#Extract unique characters (nuleotides) present in sequences\n",
    "\n",
    "unique_chars = set(''.join(sequences))\n",
    "\n",
    "#Display unique characters\n",
    "print(\"Unique Charactrs:\", unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5: MAPPING\n",
    "\n",
    "#Create mappings from characters to numerical values and vice versa\n",
    "\n",
    "char_to_int = {char: i for i, char in enumerate(sorted(unique_chars))}\n",
    "int_to_char = {i: char for char, i in char_to_int.items()}\n",
    "\n",
    "#Display mappings\n",
    "print(\"Character to Integer Mapping:\", char_to_int )\n",
    "print(\"Integer to Character Mapping:\", int_to_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 6:  ENCODE THE LABELS\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data['encoded_label'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "# Get the number of classes\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 7: CREATE A TOKENIZER AND FIT IT ON THE SEQUENCES\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True)  # Character-level tokenization\n",
    "tokenizer.fit_on_texts(data['sequence'])\n",
    "\n",
    "# Convert sequences to integer format\n",
    "X = tokenizer.texts_to_sequences(data['sequence'])\n",
    "max_seq_length = max([len(seq) for seq in X])  # Get the max sequence length\n",
    "X = pad_sequences(X, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y = to_categorical(data['encoded_label'], num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 8: SPLIT THE DATASET INTO TRAINING AND VALIDATION SETS\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 9: DEFINE MODEL PARAMETERS (MODEL ARCHITECHTURE)\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 10: TRAIN THE MODEL\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=32, \n",
    "                    validation_split=0.2, \n",
    "                    verbose=2,\n",
    "                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 11: CHECK THE ACCURACY ON TESTING SET\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print the accuracy of the model on the testing set\n",
    "print(f\"Accuracy on Testing Set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 12: PREDICT UNKNOWN SEQUENCES\n",
    "\n",
    "def preprocess_sequence(sequence, tokenizer, max_seq_length):\n",
    "    sequence = tokenizer.texts_to_sequences([sequence])\n",
    "    sequence = pad_sequences(sequence, maxlen=max_seq_length, padding='post')\n",
    "    return sequence\n",
    "\n",
    "def predict_protein_type(sequence, model, tokenizer, max_seq_length, label_encoder):\n",
    "    processed_sequence = preprocess_sequence(sequence, tokenizer, max_seq_length)\n",
    "    prediction = model.predict(processed_sequence)\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_index])\n",
    "    return predicted_label[0]\n",
    "\n",
    "# Example usage\n",
    "#Enter the unknown sequence to predict\n",
    "new_sequence = '' \n",
    "predicted_type = predict_protein_type(new_sequence, model, tokenizer, max_seq_length, label_encoder)\n",
    "print(\"Predicted protein type:\", predicted_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 12: INTERACTIVE INTERFACE FOR PREDICTING TYPE OF PROTEIN SEQUENCE\n",
    "\n",
    "def interactive_prediction(model, tokenizer, max_seq_length, label_encoder):\n",
    "    while True:\n",
    "        user_input = input(\"Do you want to predict a protein sequence? (yes/no): \").strip().lower()\n",
    "        if user_input == 'yes':\n",
    "            new_sequence = input(\"Please enter the protein sequence: \").strip()\n",
    "            predicted_type = predict_protein_type(new_sequence, model, tokenizer, max_seq_length, label_encoder)\n",
    "            print(\"Predicted protein type:\", predicted_type)\n",
    "        elif user_input == 'no':\n",
    "            print(\"Thank you for using the service!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
    "\n",
    "# Call the interactive prediction function\n",
    "interactive_prediction(model, tokenizer, max_seq_length, label_encoder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
